# ğŸ“‰ End-to-End Churn Prediction com Databricks & PySpark

## ğŸ¯ MotivaÃ§Ã£o TÃ©cnica
Este projeto foi desenvolvido com o intuito de simular um fluxo de trabalho real de **Big Data** e **MLOps**. O objetivo principal foi ir alÃ©m do Pandas/Scikit-Learn tradicional e consolidar a proficiÃªncia em:

* **Processamento DistribuÃ­do:** ManipulaÃ§Ã£o de grandes volumes de dados com **PySpark**.
* **Ecossistema Cloud:** UtilizaÃ§Ã£o do **Databricks** como plataforma unificada de dados.
* **Ciclo de Vida de Modelos:** ImplementaÃ§Ã£o de rastreamento de experimentos profissional com **MLflow**.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Databricks](https://img.shields.io/badge/Databricks-Platform-orange)
![PySpark](https://img.shields.io/badge/PySpark-Big%20Data-red)
![MLflow](https://img.shields.io/badge/MLflow-MLOps-blueviolet)
![Status](https://img.shields.io/badge/Status-ConcluÃ­do-success)

## ğŸ’¼ VisÃ£o Geral do NegÃ³cio
A rotatividade de clientes (Churn) Ã© um dos maiores desafios para empresas de serviÃ§os recorrentes. O custo de adquirir um novo cliente pode ser atÃ© **5 a 25 vezes maior** do que reter um existente.

O objetivo deste projeto Ã© desenvolver um pipeline de Machine Learning escalÃ¡vel utilizando o ecossistema **Databricks** para prever quais clientes tÃªm maior probabilidade de cancelar o serviÃ§o. Isso permite que a equipe de marketing tome aÃ§Ãµes preventivas direcionadas, aumentando a retenÃ§Ã£o e o *Life Time Value* (LTV).

## ğŸ› ï¸ Stack TecnolÃ³gica
Este projeto simula um ambiente de Big Data moderno:

* **Linguagem:** Python
* **Processamento DistribuÃ­do:** PySpark (Spark SQL & MLlib)
* **Ambiente de Desenvolvimento:** Databricks Free Edition
* **Experiment Tracking & Registry:** MLflow
* **Armazenamento:** Databricks

## ğŸš€ Arquitetura do Projeto

O projeto segue o fluxo padrÃ£o de ciÃªncia de dados (CRISP-DM) adaptado para Big Data:

1.  **IngestÃ£o de Dados:** AquisiÃ§Ã£o dos dados brutos disponiveis no [kaggle](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data) (CSV) para o Data Lake.
2.  **Feature Engineering** Processamento do dado bruto, em uma estrutura do tipo medallion. Bronze: Dado Bruto, Silver: Dado limpo e Agrupado, Gold: Pronto para a utilizaÃ§Ã£o
3.  **AnÃ¡lise ExploratÃ³ria (EDA):** AnÃ¡lise estatÃ­stica e identificaÃ§Ã£o de correlaÃ§Ãµes usando PySpark e Pandas (para visualizaÃ§Ã£o).
4.  **Modelagem (Machine Learning):** Treinamento de modelos classificadores (Logistic Regression, Random Forest, GBT).
      * UtilizaÃ§Ã£o de peso para lidar com classes desbalanceadas
5.  **MLOps (MLflow):** Log de parÃ¢metros, mÃ©tricas e artefatos de modelo para comparaÃ§Ã£o de experimentos.

## ğŸ“Š Resultados e MÃ©tricas

O melhor modelo selecionado foi a **RegressÃ£o Logistica**, obtendo os seguintes resultados no conjunto de teste:

| MÃ©trica | Valor | DescriÃ§Ã£o | InterpretaÃ§Ã£o |
| :--- | :--- | :--- | :--- |
| **AUC-ROC** | **0.605** | Capacidade de distinÃ§Ã£o entre classes. | Baixa distinÃ§Ã£o entre as classes |

> **Nota TÃ©cnica:** O foco atual do projeto reside na construÃ§Ã£o da **arquitetura de dados robusta e reprodutÃ­vel**. As mÃ©tricas indicam a necessidade de inclusÃ£o de novas features exÃ³genas ou aplicaÃ§Ã£o de outros modelos nas prÃ³ximas iteraÃ§Ãµes para superar este baseline.


<img src="./docs/best_auc_val.png" alt="drawing" width="50%" align="center" title="T"/>


## ğŸ“‚ Estrutura do RepositÃ³rio

```text
â”œâ”€â”€ notebooks/                            # Notebooks do Databricks
â”‚   â”œâ”€â”€ 000_setup.ipynb                   # Download dos Dados e configuraÃ§Ã£o das tabelas
â”‚   â”œâ”€â”€ 001_etl.ipynb                     # limpeza e extraÃ§Ã£o dos features
â”‚   â”œâ”€â”€ 002_eda.ipynb                     # AnÃ¡lise ExploratÃ³ria dos dados
â”‚   â”œâ”€â”€ 003_train.ipynb                   # Treinamento e Registro no MLflow de modelos default
â”‚   â”œâ”€â”€ 004_tune.ipynb                    # Rotina para otimizaÃ§Ã£o de hiperparametros - Hyperparameter Tuning (Hyperopt)
|   â””â”€â”€ 005_batch_inference.ipynb         # UtilizaÃ§Ã£o do modelo para processamento
â”œâ”€â”€ src/                                  # CÃ³digos reutilizaveis do projeto
|   â”œâ”€â”€ domain/                           # Dominios
â”‚   |   â””â”€â”€ feature_engineering.py        # ResponsÃ¡vel pela extraÃ§Ã£o dos features
|   â”œâ”€â”€ infrastructure/             
â”‚   |   â”œâ”€â”€ data_manager.py               # ResponsÃ¡vel por comunicar com o Data Lake
â”‚   |   â””â”€â”€ ml_trainer.py                 # ResponsÃ¡vel por treinar modelos do MLlib Apache Spark
|   â”œâ”€â”€ utility/             
â”‚   |   â””â”€â”€ environment.py                # Utilitario para as variaveis de ambiente do projeto
â”œâ”€â”€ .env.template/                        # Template para a criaÃ§Ã£o do .env do projeto
â”œâ”€â”€ README.md                             # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt                      # DependÃªncias utilizadas no projeto
```

## ğŸ‘£ Como Executar

1. Clone este repositÃ³rio para o seu Workspace no Databricks.

2. Crie o ```.env``` a partir do template e configure as variaveis do ambiente.

3. Execute os notebooks em ordem:

    1. Iniciando pelo ```000_setup.ipynb```
    2. Seguindo para ```001_etl.ipynb```
    3. ...

## ğŸ§  LiÃ§Ãµes Aprendidas

- **ManipulaÃ§Ã£o de Big Data**: UtilizaÃ§Ã£o de PySpark para processar dados que nÃ£o caberiam na memÃ³ria de uma mÃ¡quina local.

- **Ciclo de Vida de ML**: ImportÃ¢ncia do MLflow para rastrear dezenas de experimentos e garantir reprodutibilidade.

- **Dados Desbalanceados**: UtilizaÃ§Ã£o de pesos para treinamento e anÃ¡lise de mÃ©tricas como F1-Score e ROC AUC.

## Autor
Arthur Gabriel Capati

[LinkedIn](https://www.linkedin.com/in/arthur-gabriel-capati/)

[GitHub](https://github.com/arthurcapati)